{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec004c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 20.0.2 from /usr/lib/python3/dist-packages/pip (python 3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b2e4a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trivial-torch-tools\n",
      "  Downloading trivial_torch_tools-0.5.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: simple-namespace>=1.0.0 in /home/dhe/.local/lib/python3.8/site-packages (from trivial-torch-tools) (1.0.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/dhe/.local/lib/python3.8/site-packages (from trivial-torch-tools) (0.12.0)\n",
      "Collecting file-system-py>=0.0.6\n",
      "  Downloading file_system_py-0.0.6-py3-none-any.whl (4.3 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision>=0.9.0->trivial-torch-tools) (7.0.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /home/dhe/.local/lib/python3.8/site-packages (from torchvision>=0.9.0->trivial-torch-tools) (1.11.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision>=0.9.0->trivial-torch-tools) (2.22.0)\n",
      "Requirement already satisfied: typing-extensions in /home/dhe/.local/lib/python3.8/site-packages (from torchvision>=0.9.0->trivial-torch-tools) (4.2.0)\n",
      "Requirement already satisfied: numpy in /home/dhe/.local/lib/python3.8/site-packages (from torchvision>=0.9.0->trivial-torch-tools) (1.22.3)\n",
      "Installing collected packages: file-system-py, trivial-torch-tools\n",
      "Successfully installed file-system-py-0.0.6 trivial-torch-tools-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install trivial-torch-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c078049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdfa0031930>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch, torchvision\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a2e73a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.FashionMNIST('./files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.FashionMNIST('./files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a35fb17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trivial_torch_tools import Sequential\n",
    "from collections import OrderedDict\n",
    "globals()[\"default_device\"] = torch.device(\"cpu\")\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        layers = Sequential(input_shape = (1,28,28)) # given the input shape size\n",
    "        layers.add_module('conv1', nn.Conv2d(1, 10, kernel_size=5))\n",
    "        layers.add_module('conv1_pool', nn.MaxPool2d(2))\n",
    "        layers.add_module('relu', nn.ReLU())\n",
    "        layers.add_module('conv2', nn.Conv2d(10, 10, kernel_size=5))\n",
    "        layers.add_module('conv2_pool', nn.MaxPool2d(2))\n",
    "        layers.add_module('relu2', nn.ReLU())\n",
    "        layers.add_module(\"conv2_drop\", nn.Dropout2d())\n",
    "        layers.add_module('flatten', nn.Flatten(1)) \n",
    "        layers.add_module('fc1', nn.Linear(layers.output_size, 50))\n",
    "        layers.add_module('relu3', nn.ReLU())\n",
    "        layers.add_module('fc2', nn.Linear(layers.output_size, 10)) \n",
    "        layers.add_module('softmax', nn.LogSoftmax())\n",
    "        self.layers = layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e41d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8d9d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e24895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      torch.save(network.state_dict(), './files/model.pth')\n",
    "      torch.save(optimizer.state_dict(), './files/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de06a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f02eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "620a2c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhe/.local/lib/python3.8/site-packages/trivial_torch_tools/model.py:46: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return functools.reduce(\n",
      "/home/dhe/.local/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3096, Accuracy: 1043/10000 (10%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.297891\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.314451\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.282737\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.248799\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.197456\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.234931\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.200129\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.067367\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.040800\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 1.975181\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.843496\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.707868\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.632557\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.521806\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.329429\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.275666\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.172144\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.322632\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.075748\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.156038\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.337501\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.175636\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.981082\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.161171\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.994216\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.965823\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.888210\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.835585\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.079629\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.997153\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.860684\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 1.070168\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.787961\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.726798\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.922414\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.721965\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.961929\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.982923\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.026632\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.969119\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.659939\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.861829\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.848349\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.816190\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.645892\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 1.097352\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.878926\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.668058\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.687349\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.752419\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.801742\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.746042\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.786624\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.686683\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.827069\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.725780\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.815686\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.825212\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.750683\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.803224\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.979246\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.891464\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.947270\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.770127\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.697161\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.782728\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.915555\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.823637\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.788124\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.723530\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.667293\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.603693\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.763332\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.694283\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.847465\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.618773\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.913384\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.859166\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.762190\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.687774\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.003676\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.589949\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.677037\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.680137\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.943778\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.715131\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.475532\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.813164\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.658320\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.736171\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.527708\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.683381\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 1.114853\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.785366\n",
      "\n",
      "Test set: Avg. loss: 0.6330, Accuracy: 7555/10000 (76%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.027740\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.720913\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.653047\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.431222\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.556008\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.487017\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.952683\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.754429\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.539102\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.856842\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.526934\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.497252\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.724866\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.674864\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.585107\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.545198\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.929529\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.687823\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.709367\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.646865\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.664191\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.713579\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.791473\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.656106\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.775713\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.685691\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.865040\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.554129\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.520504\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.463921\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.727678\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.985768\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.569834\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.778413\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.575303\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.608066\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.560014\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.646790\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.625270\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.740588\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.653495\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.606462\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.797293\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.598055\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.759082\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.721567\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.539285\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.579774\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.723067\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.552928\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.552059\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.778123\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.635360\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.621288\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.487235\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.602567\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.470292\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.569576\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.596455\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.713386\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.755794\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.698358\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.629657\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.832325\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.599562\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 1.072556\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.543870\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.628988\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.671692\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.586402\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.701300\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.566895\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.587091\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.629162\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.612177\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.704945\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.607161\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.492521\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.452033\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.657552\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.554012\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.480292\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.604794\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.570303\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.580084\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.532597\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.615632\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.689682\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.528259\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.474060\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.628882\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.774888\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.656699\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.446171\n",
      "\n",
      "Test set: Avg. loss: 0.5409, Accuracy: 7927/10000 (79%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.545824\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.612000\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.607277\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.650357\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.452271\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.553249\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.554500\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.594705\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.596284\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.784635\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.489819\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.648925\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.640450\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.522076\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.600160\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.643403\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.708211\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.482600\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.488206\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.693989\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.593870\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.526485\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.648400\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.457640\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.512132\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.600011\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.551759\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.424973\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.801139\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.528211\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.643588\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.626077\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.540156\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.627462\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.576818\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.624764\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.672316\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.639430\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.609751\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.540326\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.623125\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.449408\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.520524\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.588541\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.619613\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.531836\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.600234\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.557254\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.473109\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.501382\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.797759\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.642121\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.477162\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.512087\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.445703\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.676896\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.588703\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.556107\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.425753\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.589260\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.350665\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.816288\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.520841\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.476988\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.439047\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.421562\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.489949\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.593908\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.524095\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.601252\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.415991\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.818581\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.588314\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.323615\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.639603\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.505813\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.622971\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.710417\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.467122\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.578228\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.492690\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.524903\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.618658\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.473205\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.576452\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.710818\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.539048\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.573090\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.553863\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.559353\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.839986\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.589673\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.680053\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.680066\n",
      "\n",
      "Test set: Avg. loss: 0.4895, Accuracy: 8172/10000 (82%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
